1、总结决策树模型结构

决策树是一种典型的分类方法，首先对数据进行处理， 利用归纳算法生成可读的规则和决策树，然后使用决策对新数据进行分析。

本质上决策树是通过一系列规则对数据进行分类的过程。

决策树的基本组成部分： 决策结点、 分支和叶子。

决策树的决策过程需要从决策树的根节点开始，待测数据与决策树中的特征节点进行比较，并按照比较结果选择选择下一比较分支，直到叶子节点作为最终的决策结果。

有两种树：分类树--对离散变量做决策树，回归树--对连续变量做决策树

决策树的学习过程分为三个部分：

特征选择：从训练数据的特征中选择一个特征作为当前节点的分裂标准（特征选择的标准不同产生了不同的特征决策树算法）。
决策树生成：根据所选特征评估标准，从上至下递归地生成子节点，直到数据集不可分则停止决策树停止声场。
剪枝：决策树容易过拟合，需要剪枝来缩小树的结构和规模（包括预剪枝和后剪枝）。

CLS（Concept Learning System） 

算法步骤：

1）生成一颗空决策树和一张训练样本属性集;

2）若训练样本集T 中所有的样本都属于同一类,则生成结点T , 并终止学习算法;否则

3）根据某种策略从训练样本属性表中选择属性A 作为测试属性, 生成测试结点A

4）若A的取值为v1,v2,…,vm, 则根据A 的取值的不同,将T 划分成m个子集T1,T2,…,Tm;

5）从训练样本属性表中删除属性A;

6）转步骤2, 对每个子集递归调用CLS;
